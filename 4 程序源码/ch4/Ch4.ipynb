{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data:\n",
      "    No  Lwsk  LEar  Weight\n",
      "0   1  34.0    82    3520\n",
      "1   2   NaN    63    4490\n",
      "2   3  45.0    90    2480\n",
      "3   4  28.0    91    4030\n",
      "4   5  37.0    59    8000\n",
      "5   6  39.0    52    6130\n",
      "6   7  48.0    52    5310\n",
      "7   8  47.0    49    5280\n",
      "Normalized data:\n",
      "     No  Lwsk      LEar    Weight\n",
      "0  0.0  0.30  0.785714  0.188406\n",
      "1  1.0   NaN  0.333333  0.364130\n",
      "2  2.0  0.85  0.976190  0.000000\n",
      "3  3.0  0.00  1.000000  0.280797\n",
      "4  4.0  0.45  0.238095  1.000000\n",
      "5  5.0  0.55  0.071429  0.661232\n",
      "6  6.0  1.00  0.071429  0.512681\n",
      "7  7.0  0.95  0.000000  0.507246\n"
     ]
    }
   ],
   "source": [
    "#【例4.1】读取素材CatInfo.csv，把数据进行归一化处理。\n",
    "import pandas as pd\n",
    "def MaxMinNormalization(x):\n",
    "    shapeX = x.shape \n",
    "    rows = shapeX[0]  #行数\n",
    "    cols = shapeX[1]   #列数\n",
    "    headers=list(x)     #Header行\n",
    "    result =pd.DataFrame(columns=headers)  #存放结果的空DataFrame\n",
    "    for i in range(0,rows,1):        \n",
    "        dict1={}                        #存放每一行结果的字典\n",
    "        dict1[headers[0]]=i\n",
    "        for j in range(1,cols,1):            \n",
    "            maxCol=x[headers[j]].max()  #j列最大值\n",
    "            minCol=x[headers[j]].min()   #j列最小值\n",
    "            val= (x.iloc[i,j]- minCol)/(maxCol-minCol)  #i行j列数据的归一化结果\n",
    "            dict1[headers[j]]=val                    \n",
    "        result=result.append(dict1,ignore_index=True)   #把i行结果添加到result\n",
    "    return result\n",
    "\n",
    "data1 = pd.read_csv('CatInfo.csv')\n",
    "print('original data:\\n',data1)\n",
    "newData=MaxMinNormalization(data1)\n",
    "print('Normalized data:\\n',newData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.3        0.78571429 0.1884058 ]\n",
      " [0.28571429 0.85       0.97619048 0.        ]\n",
      " [0.42857143 0.         1.         0.2807971 ]\n",
      " [0.57142857 0.45       0.23809524 1.        ]\n",
      " [0.71428571 0.55       0.07142857 0.66123188]\n",
      " [0.85714286 1.         0.07142857 0.51268116]\n",
      " [1.         0.95       0.         0.50724638]]\n"
     ]
    }
   ],
   "source": [
    "#【例4.2】去除数据集的空值并进行归一化处理。\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "data1 = pd.read_csv('CatInfo.csv')\n",
    "x=data1.dropna(axis=0)  #去除含有空值的行\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_minmax = min_max_scaler.fit_transform(x)\n",
    "print(x_minmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70710678 -1.31319831  0.67328879]\n",
      " [ 0.70710678  0.20203051  0.74039398]\n",
      " [-1.41421356  1.1111678  -1.41368277]]\n"
     ]
    }
   ],
   "source": [
    "#【例4.4】使用SKlearn的preprocessing模块对数据进行标准化处理。\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "x = np.array([[3.0,-2.0,490.0],\n",
    "            [3.0,0.5,520.0],\n",
    "            [1.0,2.0,-443.0]])\n",
    "x_scaled = preprocessing.scale(x)\n",
    "print(x_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.96884735]\n",
      " [1.         0.625      1.        ]\n",
      " [0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#【例4.5】使用preprocessing的MinMaxScaler类，将数据缩放到固定区间，默认缩放到区间 [0，1]。\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "x = np.array([[3.0,-2.0,490.0],\n",
    "            [3.0,0.5,520.0],\n",
    "            [1.0,2.0,-443.0]])\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_minmax = min_max_scaler.fit_transform(x)\n",
    "print(x_minmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.00e+00 -2.00e+00  4.90e+02]\n",
      " [ 3.00e+00  5.00e-01  5.20e+02]\n",
      " [ 1.00e+00  2.00e+00 -4.43e+02]]\n"
     ]
    }
   ],
   "source": [
    "#【例4.6】使用preprocessing的StandardScaler标准化类。\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "x = np.array([[3.0,-2.0,490.0],\n",
    "            [3.0,0.5,520.0],\n",
    "            [1.0,2.0,-443.0]])\n",
    "scaler = preprocessing.StandardScaler().fit(x)\n",
    "scaler.transform(x)  \n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_train_X 7    47.0\n",
      "3    28.0\n",
      "0    34.0\n",
      "5    39.0\n",
      "4    37.0\n",
      "Name: Lwsk, dtype: float64\n",
      "cat_train_y 7    49\n",
      "3    91\n",
      "0    82\n",
      "5    52\n",
      "4    59\n",
      "Name: LEar, dtype: int64\n",
      "cat_test_X 6    48.0\n",
      "2    45.0\n",
      "1     NaN\n",
      "Name: Lwsk, dtype: float64\n",
      "cat_test_y 6    52\n",
      "2    90\n",
      "1    63\n",
      "Name: LEar, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#【例4.7】将猫的数据集拆分成训练集和测试集。\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#导入数据\n",
    "data = pd.read_csv('CatInfo.csv',\",\")\n",
    "df=pd.DataFrame(data)\n",
    "# 划分成测试集和训练集\n",
    "cat_train_X , cat_test_X, cat_train_y ,cat_test_y = train_test_split(df['Lwsk'], df['LEar'], test_size=0.3,random_state=0)\n",
    "# 依次查看训练数据、训练标签、测试数据、测试标签\n",
    "print('cat_train_X',cat_train_X)\n",
    "print('cat_train_y',cat_train_y)\n",
    "print('cat_test_X',cat_test_X)\n",
    "print('cat_test_y',cat_test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67         1\n",
      "          1       0.00      0.00      0.00         1\n",
      "          2       1.00      0.67      0.80         3\n",
      "\n",
      "avg / total       0.70      0.60      0.61         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#【例4.8】算法精确率评估。\n",
    "from sklearn.metrics import classification_report\n",
    "y_true = [0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 2, 2, 1]\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
