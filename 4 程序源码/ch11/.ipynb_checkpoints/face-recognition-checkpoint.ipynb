{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本例使用的Olivetti Faces人脸图像\n",
    "![faces](faces.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Step1 |: Get dataset...\n",
      "| Step2 |: Init CNN model...\n",
      "self.dataset.X_train.shape[1:] (1, 57, 47)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 1, 57, 32)         37632     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1, 57, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 29, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 29, 64)         51264     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 29, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 15, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               492032    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 3078      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 584,006\n",
      "Trainable params: 584,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "| Step3 |: Train CNN model...\n",
      "Train on 48 samples\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 1.8413 - accuracy: 0.1667\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.7351 - accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.7077 - accuracy: 0.3750\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 1.6300 - accuracy: 0.4792\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 1.4913 - accuracy: 0.5833\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 1.2513 - accuracy: 0.7292\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.9661 - accuracy: 0.8125\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.7228 - accuracy: 0.8333\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.6332 - accuracy: 0.8542\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.3477 - accuracy: 0.9375\n",
      "12/1 [========================================================================================================================================================================================================================================================================================================================================================================] - 0s 8ms/sample - loss: 0.4202 - accuracy: 0.8333\n",
      "| Step4 |: Evaluate performance...\n",
      "===================================\n",
      "Loss   Value   is : 0.4201585352420807\n",
      "Accuracy Value is : 0.8333333\n",
      "| Step5 |: Save model...\n",
      "Model  face_recognition.h5 is succeesfuly saved.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "# 读取人脸图片数据\n",
    "def img2vector(fileNamestr):\n",
    "    # 创建向量\n",
    "    returnVect = np.zeros((57,47))    \n",
    "    image = Image.open(fileNamestr).convert('L')    \n",
    "    img = np.asarray(image).reshape(57,47)    \n",
    "    return img\n",
    "\n",
    "# 制作人脸数据集\n",
    "def GetDataset(imgDataDir):   \n",
    "    print('| Step1 |: Get dataset...')\n",
    "    imgDataDir='faces_4/'\n",
    "    FileDir = listdir(imgDataDir)\n",
    "\n",
    "    m = len(FileDir)\n",
    "    imgarray=[]\n",
    "    hwLabels=[]\n",
    "    hwdata=[]\n",
    "\n",
    "    # 逐个读取图片文件\n",
    "    for i in range(m):\n",
    "        # 提取子目录\n",
    "        className=i\n",
    "        subdirName='faces_4/'+str(FileDir[i])+'/'\n",
    "        fileNames = listdir(subdirName)                \n",
    "        lenFiles=len(fileNames)\n",
    "        # 提取文件名\n",
    "        for j in range(lenFiles): \n",
    "            fileNamestr = subdirName+fileNames[j]\n",
    "            hwLabels.append(className)    \n",
    "            imgarray=img2vector(fileNamestr)\n",
    "            hwdata.append(imgarray)\n",
    "\n",
    "    hwdata = np.array(hwdata)\n",
    "    return hwdata,hwLabels,6\n",
    "\n",
    "# CNN模型类\n",
    "class MyCNN(object):\n",
    "    FILE_PATH = \"face_recognition.h5\"  # 模型存储/读取目录\n",
    "    picHeight = 57  # 模型的人脸图片长47，宽57\n",
    "    picWidth = 47  \n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    # 获取训练数据集\n",
    "    def read_trainData(self, dataset):        \n",
    "        self.dataset = dataset\n",
    "\n",
    "    # 建立Sequential模型，并赋予参数\n",
    "    def build_model(self):\n",
    "        print('| Step2 |: Init CNN model...')\n",
    "        self.model = Sequential()\n",
    "        print('self.dataset.X_train.shape[1:]',self.dataset.X_train.shape[1:])\n",
    "        self.model.add( Convolution2D( filters=32,\n",
    "                                      kernel_size=(5, 5),\n",
    "                                      padding='same',\n",
    "                                      #dim_ordering='th',\n",
    "                                      input_shape=self.dataset.X_train.shape[1:]))\n",
    "\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add( MaxPooling2D(pool_size=(2, 2),\n",
    "                                     strides=(2, 2),\n",
    "                                     padding='same' ) )\n",
    "        self.model.add(Convolution2D(filters=64, \n",
    "                                     kernel_size=(5, 5), \n",
    "                                     padding='same') )\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                                    strides=(2, 2), \n",
    "                                    padding='same') )\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(512))\n",
    "        self.model.add(Activation('relu'))\n",
    "\n",
    "        self.model.add(Dense(self.dataset.num_classes))\n",
    "        self.model.add(Activation('softmax'))\n",
    "        self.model.summary()\n",
    "\n",
    "    # 模型训练\n",
    "    def train_model(self):\n",
    "        print('| Step3 |: Train CNN model...')\n",
    "        self.model.compile( optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        # epochs：训练代次、batch_size：每次训练样本数\n",
    "        self.model.fit(self.dataset.X_train, self.dataset.Y_train, epochs=10, batch_size=20)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        loss, accuracy = self.model.evaluate(self.dataset.X_test, self.dataset.Y_test)\n",
    "        print('| Step4 |: Evaluate performance...')\n",
    "        print('===================================')        \n",
    "        print('Loss   Value   is :', loss)\n",
    "        print('Accuracy Value is :', accuracy)\n",
    "\n",
    "    def save(self, file_path=FILE_PATH):        \n",
    "        print('| Step5 |: Save model...')\n",
    "        self.model.save(file_path)\n",
    "        print('Model ',file_path,'is succeesfuly saved.')\n",
    "\n",
    "# 建立一个用于存储和格式化读取训练数据的类\n",
    "class DataSet(object):\n",
    "    def __init__(self, path):\n",
    "        self.num_classes = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.Y_train = None\n",
    "        self.Y_test = None\n",
    "        self.picWidth = 47\n",
    "        self.picHeight = 57        \n",
    "        self.makeDataSet(path)  # 在这个类初始化的过程中读取path下的训练数据\n",
    "\n",
    "    def makeDataSet(self, path):\n",
    "        # 根据指定路径读取出图片、标签和类别数\n",
    "        imgs, labels, clasNum = GetDataset(path)\n",
    "\n",
    "        # 将数据集打乱随机分组\n",
    "        X_train, X_test, y_train, y_test = train_test_split(imgs, labels, test_size=0.2,random_state=1)\n",
    "\n",
    "        # 重新格式化和标准化\n",
    "        X_train = X_train.reshape(X_train.shape[0], 1, self.picHeight, self.picWidth) / 255.0\n",
    "        X_test = X_test.reshape(X_test.shape[0], 1, self.picHeight, self.picWidth) / 255.0\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "\n",
    "        # 将labels转成 binary class matrices\n",
    "        Y_train = np_utils.to_categorical(y_train, num_classes=clasNum)\n",
    "        Y_test = np_utils.to_categorical(y_test, num_classes=clasNum)\n",
    "\n",
    "        # 将格式化后的数据赋值给类的属性上\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_train = Y_train\n",
    "        self.Y_test = Y_test\n",
    "        self.num_classes = clasNum\n",
    "# 人脸图片目录\n",
    "dataset = DataSet('faces_4/')\n",
    "model = MyCNN()\n",
    "model.read_trainData(dataset)\n",
    "model.build_model()\n",
    "model.train_model()\n",
    "model.evaluate_model()\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人脸识别结果\n",
    "![faces_who.png](faces_who.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Step1 |: Get dataset...\n",
      "| Step3 |: Predicting......\n",
      "The predict result is Person 6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "hwdata = []\n",
    "hwLabels = []\n",
    "clasNum = 0     # 人物标签（编号0~5）\n",
    "picHeight = 57   #图像高度\n",
    "picWidth = 47   # 图像宽度\n",
    "\n",
    "# 根据指定路径读取出图片、标签和类别数\n",
    "hwdata, hwLabels, clasNum = GetDataset('faces_4/')\n",
    "\n",
    "#加载模型\n",
    "if os.path.exists('face_recognition.h5'):\n",
    "    model = load_model('face_recognition.h5')\n",
    "else:\n",
    "    print('build model first')\n",
    "\n",
    "#加载待判断图片\n",
    "photo = cv2.imread('who.jpg')\n",
    "#待判断图片调整\n",
    "resized_photo = cv2.resize(photo, (picHeight, picWidth))   # 调整图像大小\n",
    "recolord_photo = cv2.cvtColor(resized_photo, cv2.COLOR_BGR2GRAY)  # 将图像调整成灰度图\n",
    "recolord_photo = recolord_photo.reshape((1,1,picHeight,picWidth))\n",
    "recolord_photo = recolord_photo / 255.0\n",
    "#人物预测\n",
    "print('| Step3 |: Predicting......')\n",
    "result=model.predict_proba(recolord_photo)\n",
    "max_index=np.argmax(result)\n",
    "#显示结果\n",
    "print('The predict result is Person',max_index+1)\n",
    "\n",
    "cv2.namedWindow(\"testperson\",0);\n",
    "cv2.resizeWindow(\"testperson\", 300,350);\n",
    "cv2.imshow('testperson',photo)\n",
    "cv2.namedWindow(\"PredictResult\",0);\n",
    "cv2.resizeWindow(\"PredictResult\", 300,350);\n",
    "\n",
    "cv2.imshow(\"PredictResult\",hwdata[max_index*10])\n",
    "#print(resultFile)\n",
    "k = cv2.waitKey(0)\n",
    "if k == 27:         #按Esc键直接退出\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
